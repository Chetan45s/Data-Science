{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emoji Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'üî•'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.emojize(\":fire:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('dataset/train_emoji.csv',header=None)\n",
    "test = pd.read_csv('dataset/test_emoji.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict to match a number with the emoji for training purpose\n",
    "\n",
    "emoji_dictionary = {\n",
    "    \"0\": \"\\u2764\\uFE0F\",    # :heart: prints a black instead of red heart depending on the font\n",
    "    \"1\": \":baseball:\",\n",
    "    \"2\": \":beaming_face_with_smiling_eyes:\",\n",
    "    \"3\": \":downcast_face_with_sweat:\",\n",
    "    \"4\": \":fork_and_knife:\",\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train[0].values\n",
    "y_train = train[1].values\n",
    "\n",
    "x_test = test[0].values\n",
    "y_test = test[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we use glove.6B.50d.txt for embedding\n",
    "\n",
    "f = open('glove.6B.50d.txt',encoding='utf-8')\n",
    "\n",
    "embeddings_index = {}\n",
    "cnt = 0\n",
    "\n",
    "for line in f:\n",
    "    \n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:],dtype='float')\n",
    "    embeddings_index[word] = coefs\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.070292,  1.6078  ,  0.64854 , -0.4591  , -0.16151 , -1.093   ,\n",
       "        0.61743 ,  0.048792, -0.47594 ,  1.2585  , -0.52256 ,  0.96757 ,\n",
       "       -0.70143 ,  0.31107 ,  0.13962 ,  0.72396 ,  0.21441 , -0.019466,\n",
       "        0.40694 ,  0.94655 , -0.89237 ,  0.30974 ,  1.8434  ,  0.54281 ,\n",
       "        0.60901 , -1.867   , -1.9405  ,  0.71482 , -0.090765, -1.5403  ,\n",
       "        1.287   ,  0.79188 , -0.069779,  1.3083  ,  0.54165 , -0.94769 ,\n",
       "        0.90328 ,  0.18304 ,  0.87004 ,  0.46736 , -0.32235 ,  0.69321 ,\n",
       "       -0.25275 , -0.17076 ,  0.52085 ,  0.30456 , -0.47081 , -0.64507 ,\n",
       "        0.49646 ,  0.71087 ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index[\"oh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Sentences into vectors\n",
    "\n",
    "def embedding_output(x):\n",
    "    \n",
    "    maxlen = 10\n",
    "    emd_dim = 50\n",
    "    \n",
    "    embedding_out = np.zeros((x.shape[0],maxlen,emd_dim))\n",
    "    \n",
    "    for sent in range(x.shape[0]):\n",
    "        \n",
    "        x[sent] = x[sent].split()\n",
    "        \n",
    "        for word in range(len(x[sent])):\n",
    "            \n",
    "            try:\n",
    "                embedding_out[sent][word] = embeddings_index[x[sent][word].lower()]\n",
    "            except:\n",
    "                embedding_out[sent][word] = np.zeros((50,))\n",
    "                \n",
    "                \n",
    "                \n",
    "    return embedding_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_matrix_train = embedding_output(x_train)\n",
    "embeddings_matrix_test = embedding_output(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 10, 50)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_matrix_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(train[1])\n",
    "y_test = to_categorical(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 10, 64)            29440     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 62,789\n",
      "Trainable params: 62,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Traing out model\n",
    "\n",
    "# Here we are using Stacked LSTM : Where we are using y hat input of fitst cell of first Layer of LSTM as the input to the \n",
    "# first cell of LSTM of Second Layer.\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64,input_shape=(10,50),return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64,return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "4/4 [==============================] - 3s 206ms/step - loss: 1.6134 - acc: 0.2345 - val_loss: 1.5890 - val_acc: 0.2857\n",
      "Epoch 2/40\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.5666 - acc: 0.3484 - val_loss: 1.6187 - val_acc: 0.2143\n",
      "Epoch 3/40\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.5362 - acc: 0.3353 - val_loss: 1.6562 - val_acc: 0.0714\n",
      "Epoch 4/40\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.5138 - acc: 0.3301 - val_loss: 1.6743 - val_acc: 0.0714\n",
      "Epoch 5/40\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.4660 - acc: 0.3473 - val_loss: 1.6298 - val_acc: 0.1429\n",
      "Epoch 6/40\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.4087 - acc: 0.4369 - val_loss: 1.5610 - val_acc: 0.2857\n",
      "Epoch 7/40\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.3375 - acc: 0.4270 - val_loss: 1.5023 - val_acc: 0.2857\n",
      "Epoch 8/40\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.2785 - acc: 0.5177 - val_loss: 1.4354 - val_acc: 0.2857\n",
      "Epoch 9/40\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.2054 - acc: 0.4875 - val_loss: 1.3920 - val_acc: 0.4286\n",
      "Epoch 10/40\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 1.1605 - acc: 0.5341 - val_loss: 1.2944 - val_acc: 0.5000\n",
      "Epoch 11/40\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0795 - acc: 0.5982 - val_loss: 1.3271 - val_acc: 0.5000\n",
      "Epoch 12/40\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0240 - acc: 0.6034 - val_loss: 1.1300 - val_acc: 0.5714\n",
      "Epoch 13/40\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.9155 - acc: 0.6660 - val_loss: 1.1774 - val_acc: 0.5000\n",
      "Epoch 14/40\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.9001 - acc: 0.6688 - val_loss: 1.2175 - val_acc: 0.5000\n",
      "Epoch 15/40\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7613 - acc: 0.6978 - val_loss: 1.0030 - val_acc: 0.5714\n",
      "Epoch 16/40\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6856 - acc: 0.7777 - val_loss: 1.0796 - val_acc: 0.5714\n",
      "Epoch 17/40\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6470 - acc: 0.8046 - val_loss: 0.9984 - val_acc: 0.7143\n",
      "Epoch 18/40\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6557 - acc: 0.7963 - val_loss: 0.8601 - val_acc: 0.6429\n",
      "Epoch 19/40\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5788 - acc: 0.8069 - val_loss: 0.7610 - val_acc: 0.8571\n",
      "Epoch 20/40\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4356 - acc: 0.8580 - val_loss: 0.9550 - val_acc: 0.7143\n",
      "Epoch 21/40\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3970 - acc: 0.8538 - val_loss: 0.6271 - val_acc: 0.8571\n",
      "Epoch 22/40\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4002 - acc: 0.8525 - val_loss: 0.6410 - val_acc: 0.7857\n",
      "Epoch 23/40\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4151 - acc: 0.8674 - val_loss: 0.7903 - val_acc: 0.7857\n",
      "Epoch 24/40\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4112 - acc: 0.8585 - val_loss: 1.4519 - val_acc: 0.5000\n",
      "Epoch 25/40\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4612 - acc: 0.7999 - val_loss: 0.6871 - val_acc: 0.7857\n",
      "Epoch 26/40\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.3761 - acc: 0.8403 - val_loss: 0.8355 - val_acc: 0.7143\n",
      "Epoch 27/40\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3533 - acc: 0.8439 - val_loss: 1.2522 - val_acc: 0.5714\n",
      "Epoch 28/40\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3260 - acc: 0.8854 - val_loss: 0.6098 - val_acc: 0.8571\n",
      "Epoch 29/40\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.2813 - acc: 0.9231 - val_loss: 0.7261 - val_acc: 0.7857\n",
      "Epoch 30/40\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.2014 - acc: 0.9385 - val_loss: 0.9863 - val_acc: 0.6429\n",
      "Epoch 31/40\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1547 - acc: 0.9375 - val_loss: 0.9076 - val_acc: 0.6429\n",
      "Epoch 32/40\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2058 - acc: 0.9294 - val_loss: 0.8925 - val_acc: 0.7857\n",
      "Epoch 33/40\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2159 - acc: 0.9500 - val_loss: 0.9398 - val_acc: 0.7857\n",
      "Epoch 34/40\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.2127 - acc: 0.9265 - val_loss: 0.8717 - val_acc: 0.6429\n",
      "Epoch 35/40\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.1591 - acc: 0.9255 - val_loss: 1.0416 - val_acc: 0.7143\n",
      "Epoch 36/40\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1380 - acc: 0.9411 - val_loss: 1.2105 - val_acc: 0.7143\n",
      "Epoch 37/40\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1196 - acc: 0.9763 - val_loss: 0.5300 - val_acc: 0.7857\n",
      "Epoch 38/40\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1813 - acc: 0.9309 - val_loss: 1.5204 - val_acc: 0.5714\n",
      "Epoch 39/40\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1766 - acc: 0.9156 - val_loss: 1.1432 - val_acc: 0.6429\n",
      "Epoch 40/40\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1118 - acc: 0.9445 - val_loss: 0.4199 - val_acc: 0.7857\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "hist = model.fit(embeddings_matrix_train,y_train,batch_size=32,epochs=40,shuffle=True,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 1.2689 - acc: 0.6786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2688804864883423, 0.6785714030265808]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(embeddings_matrix_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(embeddings_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to eat\n",
      "üç¥\n",
      "üç¥\n",
      "he did not answer\n",
      "üòì\n",
      "üòì\n",
      "he got a raise\n",
      "üòÅ\n",
      "üòì\n",
      "she got me a present\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "ha ha ha it was so funny\n",
      "üòÅ\n",
      "üòÅ\n",
      "he is a good friend\n",
      "‚ù§Ô∏è\n",
      "üòÅ\n",
      "I am upset\n",
      "‚ù§Ô∏è\n",
      "üòì\n",
      "We had such a lovely dinner tonight\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "where is the food\n",
      "üç¥\n",
      "üç¥\n",
      "Stop making this joke ha ha ha\n",
      "üòÅ\n",
      "üòÅ\n",
      "where is the ball\n",
      "‚öæ\n",
      "‚öæ\n",
      "work is hard\n",
      "üòì\n",
      "üòÅ\n",
      "This girl is messing with me\n",
      "üòì\n",
      "üòì\n",
      "are you serious ha ha\n",
      "üòÅ\n",
      "üòì\n",
      "Let us go play baseball\n",
      "‚öæ\n",
      "‚öæ\n",
      "This stupid grader is not working\n",
      "üòì\n",
      "üòì\n",
      "work is horrible\n",
      "üòì\n",
      "üòì\n",
      "Congratulation for having a baby\n",
      "üòÅ\n",
      "üòÅ\n",
      "stop messing around\n",
      "üòì\n",
      "üòì\n",
      "any suggestions for dinner\n",
      "üç¥\n",
      "üòÅ\n",
      "I love taking breaks\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "you brighten my day\n",
      "üòÅ\n",
      "‚ù§Ô∏è\n",
      "I boiled rice\n",
      "üç¥\n",
      "üç¥\n",
      "she is a bully\n",
      "üòì\n",
      "üòì\n",
      "Why are you feeling bad\n",
      "üòì\n",
      "üòì\n",
      "I am upset\n",
      "üòì\n",
      "üòì\n",
      "I worked during my birthday\n",
      "üòì\n",
      "üòÅ\n",
      "My grandmother is the love of my life\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "enjoy your break\n",
      "üòÅ\n",
      "‚öæ\n",
      "valentine day is near\n",
      "‚ù§Ô∏è\n",
      "üòÅ\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print(' '.join(x_test[i]))\n",
    "    print(emoji.emojize(emoji_dictionary[str(np.argmax(y_test[i]))]))\n",
    "    print(emoji.emojize(emoji_dictionary[str(pred[i])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbasecondabd9cb73d6b9d45e9b9832ff240b95403"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
